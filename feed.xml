<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.0">Jekyll</generator><link href="https://mode19.github.io/humanreadable/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mode19.github.io/humanreadable/" rel="alternate" type="text/html" /><updated>2018-03-04T21:22:42-05:00</updated><id>https://mode19.github.io/humanreadable/</id><title type="html">HumanReadable Blog</title><subtitle>Computers, Linux, open-source, programming, technology and related articles</subtitle><entry><title type="html">Quick and Dirty Software Metrics using Awk</title><link href="https://mode19.github.io/humanreadable/awk,/unix/2018/03/01/Quick-and-dirty-software-metrics-using-awk.html" rel="alternate" type="text/html" title="Quick and Dirty Software Metrics using Awk" /><published>2018-03-01T00:00:00-05:00</published><updated>2018-03-01T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/awk,/unix/2018/03/01/Quick-and-dirty-software-metrics-using-awk</id><content type="html" xml:base="https://mode19.github.io/humanreadable/awk,/unix/2018/03/01/Quick-and-dirty-software-metrics-using-awk.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When troubleshooting software we don’t often have the luxury of a metrics dashboard or a monitoring system. Frequently we are patching together data from different sources and using only command-line access. The UNIX command line has lots of great text processing utilities such as cat, tail, grep, awk etc, however, numerical analysis can be challenging on the command-line.
  In this example we show how to calculate basic metrics such as average/median/minimum and maximum using an awk script.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Basic familiarity with UNIX command line such as cat, tail, grep etc&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;given-a-list-of-numbers-what-are-the-average-minimum-and-maximum-values&quot;&gt;Given a List of Numbers what are the Average, Minimum and Maximum values?&lt;/h2&gt;

&lt;p&gt;Given the following file numbers.txt. How do we quickly calculate the average or maximum value?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat numbers.txt
22
12.1
11
12
3434
29343
138
392
19342
23991
19923
23
9144
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can &lt;a href=&quot;https://en.wikipedia.org/wiki/Cat_(Unix)&quot;&gt;cat&lt;/a&gt; the file to standard output and pipe the data into our calc.sh script as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat numbers.txt | ~/bin/calc.sh 
sum     count   avg     median  min     max
105787  13      8137.47 392     11      29343
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lets look at how to create our own calc.sh script using the UNIX text processing utility awk.&lt;/p&gt;

&lt;h2 id=&quot;what-is-awk&quot;&gt;What is awk&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/AWK&quot;&gt;Awk&lt;/a&gt; is command-line text processor that can be used to quickly process text input. An awk program works by parsing an input file into records and each record is broken down into fields. By default, records are delimited by new line characters and fields are demarcated by any white-space characters. However, records and fields can be controlled by the awk RS (record-separator) and FS (field-separator) variables. By default the separators are character types, but can also be regular expressions.&lt;/p&gt;

&lt;p&gt;Once the data is parsed into records and fields and awk program consists of condition-command pairs that are applied to each input record. If the condition is true for that record then the command is executed. The program is over when all the records have been processed making it ideal for filtering or counting of events.&lt;/p&gt;

&lt;p&gt;In addition to processing for each record a BEGIN and END section are executed unconditionally before and after processing of the records.&lt;/p&gt;

&lt;p&gt;Lets dive right into our program to see an example.&lt;/p&gt;

&lt;h2 id=&quot;using-awk-to-measure-average-minimum-maximum-and-medium-times&quot;&gt;Using awk to measure Average, Minimum, Maximum and Medium times&lt;/h2&gt;

&lt;p&gt;Copy the following awk script into your ~/bin/calc.sh file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# This bash script expects to be fed a line-separated list of numbers and will print out the sum/count/average/medium/min/max encountered.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# based on a script from: https://unix.stackexchange.com/questions/13731/is-there-a-way-to-get-the-min-max-median-and-average-of-a-list-of-numbers-in&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'
  BEGIN {
    c = 0;
    sum = 0;
    OFS=&quot;\t&quot;;
    print &quot;sum&quot;,&quot;count&quot;, &quot;average&quot;, &quot;medium&quot;, &quot;min&quot;, &quot;max&quot;
  }
  $1 ~ /^[0-9]*(\.[0-9]*)?$/ {
    a[c++] = $1;
    sum += $1;
  }
  END {
    ave = sum / c;
    if( (c % 2) == 1 ) {
      median = a[ int(c/2) ];
    } else {
      median = ( a[c/2] + a[c/2-1] ) / 2;
    }
    print sum, c, ave, median, a[0], a[c-1];
}
'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Don’t forget to assign executable permission to the script:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chmod +x ~/bin/calc.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-begin-section&quot;&gt;The BEGIN Section&lt;/h2&gt;
&lt;p&gt;The first block of the program called ‘BEGIN’ is a special section that gets executed before any records are processed. In this case we use the begin block to initialize two variables to 0 and to print out a header line to standard output.&lt;/p&gt;

&lt;h2 id=&quot;the-middle-block&quot;&gt;The Middle Block&lt;/h2&gt;
&lt;p&gt;The middle section of the program is an awk condition-command pair that gets executed for every input record. Lets look at the awk condition in detail: ‘$1 ~ /&lt;REGULAREXPRESSION&gt;/':&lt;/REGULAREXPRESSION&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Awk condition component&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$1&lt;/td&gt;
      &lt;td&gt;$1 in awk represents the first field encountered in this record.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;~&lt;/td&gt;
      &lt;td&gt;A ~ character attempts to match a value to a regular expression&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/ regular-expression  /&lt;/td&gt;
      &lt;td&gt;The regular expression is written between two ‘/’ characters&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
The regular expression ^[0-9]&lt;em&gt;(.[0-9]&lt;/em&gt;)?$ will match all numbers and exclude any input lines which are non numbers or contain non-numeric characters (See table below for details).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Regular Expression Component&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;^&lt;/td&gt;
      &lt;td&gt;Regular expression to match from the beginning of the field&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[0-9]*&lt;/td&gt;
      &lt;td&gt;Match a series of numbers&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;(.[0-9]*)?&lt;/td&gt;
      &lt;td&gt;Match an optional decimal component to the number&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$&lt;/td&gt;
      &lt;td&gt;Marks the end of the field&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The expression above ensures every number that appears in the input is processed by our awk command ‘a[c++] = $1’. With this command we are saving each input field into an array so that we can calculate the median later. Also by incrementing a ‘sum’ variable we are keeping a running total of all values encountered.&lt;/p&gt;

&lt;h2 id=&quot;the-end-block&quot;&gt;The END Block&lt;/h2&gt;
&lt;p&gt;The END section is executed after all input records have been processed. After processing each record we have an array called ‘a’ which contains every number encountered on the input. Since the first command in the script (before invoking awk) is &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort_(Unix)&quot;&gt;sort&lt;/a&gt; we know the array is ordered, which makes finding the min and max as simple as grabbing the first and last item of the array.&lt;/p&gt;

&lt;h2 id=&quot;conclusion-and-next-steps&quot;&gt;Conclusion and Next Steps&lt;/h2&gt;
&lt;p&gt;Using the above awk script we can quickly analyze numeric values on the command line. Also, we can incorporate basic performance metrics into automated scripts.&lt;/p&gt;</content><author><name></name></author><summary type="html">Introduction When troubleshooting software we don’t often have the luxury of a metrics dashboard or a monitoring system. Frequently we are patching together data from different sources and using only command-line access. The UNIX command line has lots of great text processing utilities such as cat, tail, grep, awk etc, however, numerical analysis can be challenging on the command-line. In this example we show how to calculate basic metrics such as average/median/minimum and maximum using an awk script.</summary></entry><entry><title type="html">VIM Quick Tip: The Global Command</title><link href="https://mode19.github.io/humanreadable/vim/2018/01/09/vim-global-commmand.html" rel="alternate" type="text/html" title="VIM Quick Tip: The Global Command" /><published>2018-01-09T00:00:00-05:00</published><updated>2018-01-09T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/vim/2018/01/09/vim-global-commmand</id><content type="html" xml:base="https://mode19.github.io/humanreadable/vim/2018/01/09/vim-global-commmand.html">&lt;p&gt;For vim users, one of the most useful commands to know is the global command. The global command applies an operation to all lines which match (or do not match) a specified pattern.&lt;/p&gt;

&lt;p&gt;To see the formal help page enter the following into vim:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;help :g
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The example below looks specifically at the delete (or ‘d’) command, but there are many others that can be used.  To see more commands enter:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;help ex-cmd-index
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A common use is to delete lines from a file matching a pattern.  For example:&lt;/p&gt;

&lt;p&gt;If we wanted to remove all the lines containing ‘grapefruit’ from the following file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Michael Jackson
grapefruit1
Joe Cocker
grapefruit2
Bruce Springsteen
grapefruit3
Aretha Franklin
grapefruit4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;we would enter the command&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;:g/grapefruit/d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and be left with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Michael Jackson
Joe Cocker
Bruce Springsteen
Aretha Franklin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, we could remove the lines NOT containing ‘grapefruit’ as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;:g!/grapefruit/d 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and be left with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;grapefruit1
grapefruit2
grapefruit3
grapefruit4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using more complex patterns can make this command invaluable when cleaning up data files.&lt;/p&gt;</content><author><name></name></author><summary type="html">For vim users, one of the most useful commands to know is the global command. The global command applies an operation to all lines which match (or do not match) a specified pattern.</summary></entry><entry><title type="html">JavaScript Quick Tip: Stringifying an Object with Indentation</title><link href="https://mode19.github.io/humanreadable/javascript/2018/01/09/javascript-JSON-formatting.html" rel="alternate" type="text/html" title="JavaScript Quick Tip: Stringifying an Object with Indentation" /><published>2018-01-09T00:00:00-05:00</published><updated>2018-01-09T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/javascript/2018/01/09/javascript-JSON-formatting</id><content type="html" xml:base="https://mode19.github.io/humanreadable/javascript/2018/01/09/javascript-JSON-formatting.html">&lt;p&gt;In JavaScript the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify&quot;&gt;JSON.stringify&lt;/a&gt; method provides a way of converting a JavaScript object to a string.  This function also has a feature to add linebreaks and indentation as a quick way to make the string more readable which can help during troubleshooting.&lt;/p&gt;

&lt;p&gt;For example, take the following JavaScript object:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;obj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
 &lt;span class=&quot;na&quot;&gt;arr&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Pass it to the stringify function with the following parameters:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The end result is a string that is indented and formatted as a readable string:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;test&quot;: 1,
    &quot;arr&quot;: [
        {
            &quot;a&quot;: 1
        },
        {
            &quot;b&quot;: 2
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">In JavaScript the JSON.stringify method provides a way of converting a JavaScript object to a string. This function also has a feature to add linebreaks and indentation as a quick way to make the string more readable which can help during troubleshooting.</summary></entry><entry><title type="html">Manage your News Feeds with Newsbeuter and DigitalOcean</title><link href="https://mode19.github.io/humanreadable/rss,digitalocean/2017/11/14/manage-newsfeeds-with-newsbeuter-and-digitalocean.html" rel="alternate" type="text/html" title="Manage your News Feeds with Newsbeuter and DigitalOcean" /><published>2017-11-14T00:00:00-05:00</published><updated>2017-11-14T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/rss,digitalocean/2017/11/14/manage-newsfeeds-with-newsbeuter-and-digitalocean</id><content type="html" xml:base="https://mode19.github.io/humanreadable/rss,digitalocean/2017/11/14/manage-newsfeeds-with-newsbeuter-and-digitalocean.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this modern age we have unprecedented access to information through the internet.  The amount of information is so large it can be overwhelming and with the advent of personalized profiles and machine learning algorithms we are increasingly trusting software suggestions to decide which content to consume. It often seems like YouTube and Facebook know exactly which video we want to watch. This can be a convenient and fun way to be exposed to new content and ideas. However, this can also lead to distracting ads and unwanted content. This article takes a trip back in time to when the web was a younger and more idealistic place; more like a sprawling outdoor market place than a series of carefully curated big box stores. In this market place the responsibility of navigating and choosing items falls entirely on the user. How does one keep track of which stalls have new items to see? How does one filter out unwanted items? This article describes one way to use &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_feed&quot;&gt;Web Feeds&lt;/a&gt; and news reader software in order to organize your information and save you time.&lt;/p&gt;

&lt;h3 id=&quot;what-are-rss-atom-and-newsbeuter&quot;&gt;What are RSS, Atom and Newsbeuter?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/RSS&quot;&gt;RSS (Really Simple Syndication)&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Atom&quot;&gt;Atom&lt;/a&gt; are types of web feeds that allow content publishers such as websites, blogs, podcasts etc to announce to the world when new items are available. News readers are software programs that can read these syndication formats from a bunch of websites and present the results to the user much like an e-mail program.&lt;/p&gt;

&lt;p&gt;There are many news reading tools &lt;a href=&quot;https://en.wikipedia.org/wiki/News_aggregator&quot;&gt;available&lt;/a&gt;. This tutorial introduces you to &lt;a href=&quot;https://newsbeuter.org/&quot;&gt;Newsbeuter&lt;/a&gt;, a UNIX based console program.
Why Newsbeuter?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Simple text-based interface&lt;/li&gt;
  &lt;li&gt;Remotely and Securely accessible (through ssh)&lt;/li&gt;
  &lt;li&gt;No distracting images and ads&lt;/li&gt;
  &lt;li&gt;Tagging and filtering content&lt;/li&gt;
  &lt;li&gt;Query Feeds - (simplifies content into single feeds)&lt;/li&gt;
  &lt;li&gt;Open-source license &lt;a href=&quot;https://github.com/akrennmair/newsbeuter/blob/master/LICENSE&quot;&gt;github: akrennmair/newsbeuter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will walk through the process of installing and configuring Newsbeuter and by the end of the tutorial you should have an understanding of each of these features and how they can help you take back control of your news feeds.&lt;/p&gt;

&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;To perform the steps in this guide, you will need the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ability to use the Unix command line to issue commands and create as well as edit files&lt;/li&gt;
  &lt;li&gt;A Ubuntu server install such as one from DigitalOcean because they have great tutorials such as &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-16-04&quot;&gt;How to setup a Ubuntu server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-1-installing-newsbeuter&quot;&gt;Step 1: Installing Newsbeuter&lt;/h3&gt;
&lt;p&gt;Lets begin! At the &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_installation&quot;&gt;Newsbeuter website&lt;/a&gt; you will find detailed instructions for installing and configuring the software. Luckily, Ubuntu rocks, and often has a package ready for us to use, so the easiest way to get started is often to log into your server and search the package manager for Newsbeuter by entering the following command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ apt-cache search newsbeuter
newsbeuter - text mode rss feed reader with podcast support&amp;lt;/pre&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Yes, it’s there, so lets install it:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install newsbeuter
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Follow the prompts of the install and when it completes you should be able to run Newsbeuter as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ newsbeuter
XDG: configuration directory '/home/webadmin/.config/newsbeuter' not accessible, using '/home/webadmin/.newsbeuter' instead.
Starting newsbeuter 2.7...
Loading configuration...done.
Opening cache...done.
Loading URLs from /home/webadmin/.newsbeuter/urls...done.
Error: no URLs configured. Please fill the file /home/webadmin/.newsbeuter/urls with RSS feed URLs or import an OPML file.

newsbeuter 2.7
usage: newsbeuter [-i &amp;lt;file&amp;gt;|-e] [-u &amp;lt;urlfile&amp;gt;] [-c &amp;lt;cachefile&amp;gt;] [-x &amp;lt;command&amp;gt;&amp;lt;/command&amp;gt; ...] [-h]
        -e              export OPML feed to stdout
        -r              refresh feeds on start
        -i &amp;lt;file&amp;gt;       import OPML file
        -u &amp;lt;urlfile&amp;gt;    read RSS feed URLs from &amp;lt;urlfile&amp;gt;
        -c &amp;lt;cachefile&amp;gt;  use &amp;lt;cachefile&amp;gt; as cache file
        -C &amp;lt;configfile&amp;gt; read configuration from &amp;lt;configfile&amp;gt;
        -X              clean up cache thoroughly
        -x &amp;lt;command&amp;gt;&amp;lt;/command&amp;gt;... execute list of commands
        -o              activate offline mode (only applies to Google Reader synchronization mode)
        -q              quiet startup
        -v              get version information
        -l &amp;lt;loglevel&amp;gt;   write a log with a certain loglevel (valid values: 1 to 6)
        -d &amp;lt;logfile&amp;gt;    use &amp;lt;logfile&amp;gt; as output log file
        -E &amp;lt;file&amp;gt;       export list of read articles to &amp;lt;file&amp;gt;
        -I &amp;lt;file&amp;gt;       import list of read articles from &amp;lt;file&amp;gt;
        -h              this help
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The error message above explains exactly why Newsbeuter was unable to start, and then prints out the usage message. As we can see, we haven’t added any web links or &lt;a href=&quot;https://en.wikipedia.org/wiki/URL&quot;&gt;URLs&lt;/a&gt; for Newsbeuter to read. There are two ways we can do that.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We can update the ‘urls’ file&lt;/li&gt;
  &lt;li&gt;We can import the &lt;a href=&quot;https://en.wikipedia.org/wiki/OPML&quot;&gt;OPML&lt;/a&gt; file. If you previously used another RSS reader we could try to export the data from that program into an OPML file. In that case you can import it into Newsbeuter using the -i option.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lets assume we are starting from scratch and we are going to update the ‘urls’ file:&lt;/p&gt;

&lt;p&gt;~/.newsbeuter/urls&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#news
http://newsrss.bbc.co.uk/rss/newsonline_world_edition/front_page/rss.xml &quot;~BBC News&quot; news, noisy

#technology 
https://news.ycombinator.com/rss &quot;~HN&quot; news, noisy
 
#DigitalOcean stuff 
https://status.digitalocean.com/history.rss &quot;~DigitalOcean-status&quot; important
https://status.heroku.com/feed &quot;~Heroku status&quot; important

#random feeds 
http://feeds.feedburner.com/OpenCulture &quot;~OpenCulture Blog&quot; blog
http://joeroganexp.joerogan.libsynpro.com/rss &quot;~Joe Rogan Podcast&quot; podcast
http://www.nba.com/raptors/rss.xml &quot;~Raptors Schedule&quot; blog noisy
https://www.youtube.com/feeds/videos.xml?user=DigitalOceanVideos &quot;~DigitalOcean Videos - youtube&quot; blog

#health
http://nutritionfacts.org/feed &quot;~Nutrition Facts&quot; blog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Copy the text above into the &lt;code class=&quot;highlighter-rouge&quot;&gt;~/newsbeuter/urls&lt;/code&gt; file. Once we have saved the file we can try to run newsbeuter again. Now we can see our feeds:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://2.bp.blogspot.com/-6tI0ammr0Xk/WgoZwLs6Q0I/AAAAAAAAAAo/W7733oOUPTQhEGObdcqGkFOC7pz3UsjxwCEwYBhgL/s1600/newsbeuter_after_initial_refresh.png&quot; alt=&quot;Newsbeuter initial screenshot&quot; title=&quot;Newsbeuter Initial Screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Welcome to the main screen of Newsbeuter, the layout consists of three main sections.  A title bar, a list of content and at the bottom is a menu bar summarizing commands currently available.  In this case the content list contains the six feeds we added to the urls file. To get started just press &lt;kb&gt;R&lt;/kb&gt; to reload all feeds. This will go through each URL and fetch its content. In this case thousands of unread articles will appear so if you’re feeling overwhelmed just press &lt;kb&gt;C&lt;/kb&gt; to catch up and mark everything as read.  Typically you press &lt;kb&gt;R&lt;/kb&gt; to reload all your feeds to see if any new items have arrived. Press &lt;kb&gt;?&lt;/kb&gt; to get a full list of commands&lt;/p&gt;

&lt;p&gt;Newsbeuter starts off in the Feeds List View and is structured as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Feed List View
    Article List
        Article View
            Open in Browser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Press &lt;kb&gt;Enter&lt;/kb&gt; inside a feed opens the list of articles and pressing &lt;kb&gt;Enter&lt;/kb&gt; on article opens the article details etc. In all cases &lt;kb&gt;q&lt;/kb&gt; takes you back to the previous screen.&lt;/p&gt;

&lt;h3 id=&quot;configure-newsbeuter-with-your-own-settings&quot;&gt;Configure Newsbeuter with your own settings&lt;/h3&gt;
&lt;p&gt;Now we’re up and running. We can jump into Newsbeuter whenever we feel the need to get up to date information (or we may be looking to procrastinate by reading a celebrity gossip feed; which I’m sure you’re not interested in but just in case here is the URL: &lt;i&gt;http://www.tmz.com/category/hook-ups/rss.xml&lt;/i&gt;).&lt;/p&gt;

&lt;p&gt;Simply start Newsbeuter and press &lt;kb&gt;R&lt;/kb&gt; repeatedly until a new item appears. If pressing &lt;kb&gt;R&lt;/kb&gt; is too much effort we can use the auto-reload feature to periodically refresh the news item for us.&lt;/p&gt;

&lt;p&gt;The configuration settings such as auto-reload are well documented in the newsbeuter user manual, just reference the &lt;a href=&quot;https://www.newsbeuter.org/doc/newsbeuter.html#_first_steps&quot;&gt;First Steps&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;Here is an example of a working a configuration file.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.newsbeuter/config:&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# no automatic reloading
refresh-on-startup no
auto-reload no
reload-time 360 # minutes

# reloading
reload-threads 4
reload-only-visible-feeds no
#show-read-feeds no
download-retries 4

# notification
notify-screen yes
notify-xterm yes

# storage
#max-items 200

# external programs - ff is a firefox wrapper
#browser elinks %u

# display
#article-sort-order date-desc
#feedlist-format &quot;%S%n %11u %t&quot;
#articlelist-format &quot;%D %f %?T?;%-17T; ?%t&quot;
#datetime-format %m-%d
#color background white black
#color listnormal white black
#color listfocus black white
#color info black white
#color article white black

# interface
confirm-exit yes
bind-key k up
bind-key j down
bind-key O open-in-browser-and-mark-read
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;viewing-articles&quot;&gt;Viewing Articles&lt;/h3&gt;
&lt;p&gt;To view an article, simply press &lt;kb&gt;Enter&lt;/kb&gt; to open the article, and then press &lt;kb&gt;o&lt;/kb&gt; to open it in the browser. Since most of the content is text based, we can use the default w3m text based browser to read it. However, if you’re on a desktop system with Chrome or Firefox available you can just as &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_first_steps&quot;&gt;easily configure Newsbeuter&lt;/a&gt; to open that.&lt;/p&gt;

&lt;p&gt;Since the default browser is w3m here is a quick summary of the keys needed to navigate this browser:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Key&lt;/th&gt;
      &lt;th&gt;Command Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;kb&gt;q&lt;/kb&gt;&lt;/td&gt;
      &lt;td&gt;quit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;kb&gt;space&lt;/kb&gt;&lt;/td&gt;
      &lt;td&gt;page down&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;kb&gt;b&lt;/kb&gt;&lt;/td&gt;
      &lt;td&gt;page up&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;kb&gt;H&lt;/kb&gt;&lt;/td&gt;
      &lt;td&gt;help screen&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
If you want to stick with using a text based browser consider using &lt;a href=&quot;http://elinks.or.cz/&quot;&gt;elinks&lt;/a&gt;. It does a good job of rendering modern web pages for basic readability and is also available on Ubuntu.&lt;/p&gt;

&lt;h3 id=&quot;tags---categorize-your-feeds&quot;&gt;Tags - Categorize your Feeds&lt;/h3&gt;
&lt;p&gt;Tags are useful for organizing your feeds. You will notice in the urls file above that we can put a list of space separated tags after the feed name. These tags can then be used to group feeds and articles.&lt;/p&gt;

&lt;p&gt;For example, to view only items tagged with ‘important’, press &lt;kb&gt;t&lt;/kb&gt; and then select the ‘important’ the tag. Press &lt;kb&gt;Ctrl&lt;/kb&gt;+&lt;kb&gt;t&lt;/kb&gt; to clear the tag filter.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://3.bp.blogspot.com/-2WXHqISou58/Wgob2npq2BI/AAAAAAAAAA4/bhVyVcCAjh0-pOd1At4UpOTURFpyOhJEACEwYBhgL/s1600/newsbeuter_tag_importantonly.png&quot; alt=&quot;Newsbeuter tags screenshot&quot; title=&quot;Newsbeuter Tags Screen-shot&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;filters---focus-on-what-is-important&quot;&gt;Filters - Focus on what is Important&lt;/h3&gt;
&lt;p&gt;Filters can remove unwanted entries from your current view. There are two types of filters, feed filters and article filters.&lt;/p&gt;

&lt;p&gt;For example: to filter out feeds that do not contain any unread items, we can press &lt;kb&gt;F&lt;/kb&gt;, then enter the following filter text, followed by &lt;kb&gt;Enter&lt;/kb&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;unread_count &amp;gt; 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Press &lt;kb&gt;Ctrl&lt;/kb&gt;+&lt;kb&gt;F&lt;/kb&gt; to clear the filter and view everything again.&lt;/p&gt;

&lt;p&gt;Filters can be predefined in the configuration file by adding them to the config file, for example add:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.newsbueter/config&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;define-filter &quot;Articles containing 'linux'&quot; &quot;title =~ \&quot;linux\&quot;&quot;
define-filter &quot;Feeds with unread messages&quot; &quot;unread_count &amp;gt; 0&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For complete details on creating filter expressions see the &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_filter_language&quot;&gt;detailed documentation here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;simplifying-views-with-query-feeds-and-grouping&quot;&gt;Simplifying Views with Query Feeds and Grouping&lt;/h3&gt;
&lt;p&gt;Query feeds are a powerful tool that make Newsbeuter stand out as a news reader. They give the user the ability to combine a set of distinct feeds into a single feed. Once your URL list starts to grow bigger you will see why this is very useful. Instead of checking all the entertainment related feeds separately to see what updates were received for today we can open a single feed called entertainment and see them all together in a single view. Lets work through a simple example to illustrate.&lt;/p&gt;

&lt;p&gt;Add the following line to the top of the urls file and restart Newsbeuter.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.newsbeuter/urls:&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;query:Entertainment Stuff:tags # \&quot;blog\&quot; or tags # \&quot;podcast\&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above statement creates a new feed called “Entertainment Stuff” which groups together everything with blog or podcast tags. You can see in the screen-shot below that when we open “Entertainment Stuff” all the applicable articles are grouped together in one list:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://4.bp.blogspot.com/-yNcFOXpm3n4/WgodkHe-DOI/AAAAAAAAABA/zGtt1jMOnLsyW9XZ9J4CCJXECy5GYqd-wCLcBGAs/s1600/newsbeuter_query_feed_example.png&quot; alt=&quot;Newsbeuter tags screenshot&quot; title=&quot;Newsbeuter Tags Screen-shot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can write and combine filter expression as needed, see the &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_filter_language&quot;&gt;filter language documentation page&lt;/a&gt; to learn more.&lt;/p&gt;

&lt;h3 id=&quot;conclusion-and-next-steps&quot;&gt;Conclusion and Next Steps&lt;/h3&gt;
&lt;p&gt;We took a trip back in time to the age of text-based software and browsers. We learned about RSS and how to use Newsbeuter to start managing our own news feeds. There are still plenty of sites that use RSS and Atom.  Here are some ideas on what you can include in your feeds:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Blogs&lt;/li&gt;
  &lt;li&gt;News aggregators i.e slashdot.org (just make sure to make filters for these noisy sources)&lt;/li&gt;
  &lt;li&gt;Forum thread comment sections&lt;/li&gt;
  &lt;li&gt;DigitalOcean status page&lt;/li&gt;
  &lt;li&gt;YouTube channels (ok, so its hard to view youtube videos in w3m but you will be notified of new updates)&lt;/li&gt;
  &lt;li&gt;News sites&lt;/li&gt;
  &lt;li&gt;Websites like reddit, monster.com, craigslist etc etc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, Newsbeuter has many advanced features to potentially further improve your workflow. For example, &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_macro_support&quot;&gt;Newsbeuter macros&lt;/a&gt; allow you to combine a sequence of frequently used commands into a single keystroke. Also you can extend Newsbeuter’s functionality using &lt;a href=&quot;https://newsbeuter.org/doc/newsbeuter.html#_scripts_and_filters_snownews_extensions&quot;&gt;scripts&lt;/a&gt; which can execute external commands and applications from inside Newsbeuter.  Hopefully this tutorial has given you some new ideas on how to manage your news feeds and added another tool to your time management toolbox.&lt;/p&gt;</content><author><name></name></author><summary type="html">Introduction In this modern age we have unprecedented access to information through the internet. The amount of information is so large it can be overwhelming and with the advent of personalized profiles and machine learning algorithms we are increasingly trusting software suggestions to decide which content to consume. It often seems like YouTube and Facebook know exactly which video we want to watch. This can be a convenient and fun way to be exposed to new content and ideas. However, this can also lead to distracting ads and unwanted content. This article takes a trip back in time to when the web was a younger and more idealistic place; more like a sprawling outdoor market place than a series of carefully curated big box stores. In this market place the responsibility of navigating and choosing items falls entirely on the user. How does one keep track of which stalls have new items to see? How does one filter out unwanted items? This article describes one way to use Web Feeds and news reader software in order to organize your information and save you time.</summary></entry><entry><title type="html">Command-line Log Metrics: cat, grep, sed, uniq, sort, wc and awk</title><link href="https://mode19.github.io/humanreadable/awk,/unix/2017/01/01/Command-line-log-metrics.html" rel="alternate" type="text/html" title="Command-line Log Metrics: cat, grep, sed, uniq, sort, wc and awk" /><published>2017-01-01T00:00:00-05:00</published><updated>2017-01-01T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/awk,/unix/2017/01/01/Command-line-log-metrics</id><content type="html" xml:base="https://mode19.github.io/humanreadable/awk,/unix/2017/01/01/Command-line-log-metrics.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When troubleshooting software we usually don’t have all the required information in one place. Often we only have command-line access to low level application and system log files.
  Command line tools such as tail, cat, grep etc. can be combined to provide basic insights into application performance.
Lets look at some examples of how to use standard UNIX command-line tools to analyze application log files.&lt;/p&gt;

&lt;h2 id=&quot;pre-requisites&quot;&gt;Pre-requisites&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Be comfortable using the UNIX command line such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Cat_(Unix)&quot;&gt;cat&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Tail_(Unix)&quot;&gt;tail&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Grep&quot;&gt;grep&lt;/a&gt; etc.&lt;/li&gt;
  &lt;li&gt;Have access to the calc.sh script which can calculate average/median/minimum and maximum times, see the corresponding guide &lt;a href=&quot;https://mode19.github.io/humanreadable/awk,/unix/2018/03/01/Quick-and-dirty-software-metrics-using-awk.html&quot;&gt;Quick and Dirty Software Metrics using Awk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why&quot;&gt;Why?&lt;/h2&gt;

&lt;p&gt;Lets look at real world situation: a customer has complained that some operations in the system are taking too long. Luckily the developer included some logging in the application that records how long each operation takes. If we view the log file directly we can see an entry for every event that occurred. Now imagine this log contains thousands or millions of records? How will we identify which events are being triggered in the system? How frequently are certain types of events occurring? How long does each type of event take to process (Average, minimum, maximum time etc)? The below guide is a step by step example of how to calculate these kinds of metrics.&lt;/p&gt;

&lt;p&gt;Imagine a logfile that looks as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2018-03-03 12:00:14 SOFTWAREPROGRAM MODULE DEBUG [sessiony] processing event #1 took 20440 ms
2018-03-03 12:00:15 SOFTWAREPROGRAM MODULE INFO [sessionx] processing event #1 took 20440 ms
2018-03-03 12:00:16 SOFTWAREPROGRAM MODULE DEBUG [sessiony] processing event #1 took 20440 ms
2018-03-04 12:00:24 SOFTWAREPROGRAM MODULE ERROR [sessionx] processing event #1 took 20440 ms
2018-03-04 12:01:04 SOFTWAREPROGRAM MODULE DEBUG [sessiony] processing event #1 took 16628 ms
2018-03-04 12:02:53 SOFTWAREPROGRAM MODULE DEBUG [sessionx] processing event #0 took 11418 ms
2018-03-04 12:03:00 SOFTWAREPROGRAM MODULE INFO [sessiony] processing event #1 took 28995 ms
2018-03-04 12:04:44 SOFTWAREPROGRAM MODULE DEBUG [sessionx] processing event #1 took 28166 ms
2018-03-04 12:04:44 SOFTWAREPROGRAM MODULE DEBUG [sessiony] processing event #0 took 26063 ms
2018-03-04 12:04:44 SOFTWAREPROGRAM MODULE INFO [sessionx] processing event #1 took 27168 ms
2018-03-04 12:07:31 SOFTWAREPROGRAM MODULE DEBUG [sessionz] processing event #0 took 30484 ms
2018-03-04 12:08:44 SOFTWAREPROGRAM MODULE DEBUG [sessionx] processing event #1 took 27769 ms
2018-03-04 12:09:07 SOFTWAREPROGRAM MODULE DEBUG [sessionz] processing event #1 took 16378 ms

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;filtering-and-counting-events&quot;&gt;Filtering and Counting Events&lt;/h2&gt;

&lt;p&gt;When faced with thousands of records, the first step is to filter out the records we are not interested in.  We do this by identifying a set of specific key words that we are interested in, and we chose these key words so that they uniquely identify the event we are interested.  For example, searching for “event #1” might also match “event #11”, so in order to uniquely identify “\sevent #1\s” we would have to also include the surrounding white-space as part of the matching expression. In this example only 2 events so we can safely filter “event #1”. See the examples below to filter out unwanted records by using &lt;a href=&quot;https://en.wikipedia.org/wiki/Cut_(Unix)&quot;&gt;grep&lt;/a&gt; and counting the remaining ones using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Wc_(Unix)&quot;&gt;wc&lt;/a&gt; utility .&lt;/p&gt;

&lt;p&gt;How many events happened on March 3rd?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;2018-03-03&quot; | wc -l
3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How many events happened on March 2nd?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;2018-03-02&quot; | wc -l
0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How many events of type “event #1” happened on March 4th?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;2018-03-04&quot; | grep &quot;event #1&quot; | wc -l
7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How many events happened for sessionz on March 4th?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;2018-03-04&quot; | grep &quot;event #1 &quot; | grep &quot;\[sessionz\]&quot; | wc -l
1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;N.B Notice the regular expression to match the session identifier sessionz includes the surround delimiters.  This avoids situations where sessionz could become a false positive for sessionzz or sessionz1 etc.&lt;/p&gt;

&lt;h2 id=&quot;cutting-and-counting&quot;&gt;Cutting and Counting&lt;/h2&gt;

&lt;p&gt;We can use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cut_(Unix)&quot;&gt;cut&lt;/a&gt; command to isolate specific fields.  This way we can aggregate data over specific groups such as time. Using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort_(Unix)&quot;&gt;sort&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Uniq&quot;&gt;uniq&lt;/a&gt; utilities we can count the unique number of occurrences of each event by group.&lt;/p&gt;

&lt;p&gt;For example, how many events are happening per day?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt | cut -f1 -d&quot; &quot; | sort | uniq -c
3 2018-03-03
10 2018-03-04
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How many events are happening per second?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt | cut -d &quot; &quot; -f1,2   | uniq -c
1 2018-03-03 12:00:14
1 2018-03-03 12:00:15
1 2018-03-03 12:00:16
1 2018-03-04 12:00:24
1 2018-03-04 12:01:04
1 2018-03-04 12:02:53
1 2018-03-04 12:03:00
3 2018-03-04 12:04:44
1 2018-03-04 12:07:31
1 2018-03-04 12:08:44
1 2018-03-04 12:09:07
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;what-is-the-average-processing-time-of-event-0&quot;&gt;What is the Average Processing Time of Event #0?&lt;/h2&gt;

&lt;p&gt;In order to isolate the log entries containing “event #0” and identifying only the processing time we can produce a list of all corresponding processing times.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;event #0 &quot;
2018-03-04 12:2:53 SOFTWAREPROGRAM MODULE DEBUG processing event #0 took 11418 ms
2018-03-04 12:5:21 SOFTWAREPROGRAM MODULE DEBUG processing event #0 took 26063 ms
2018-03-04 12:7:31 SOFTWAREPROGRAM MODULE DEBUG processing event #0 took 30484 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What are just the response times? Using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sed&quot;&gt;sed&lt;/a&gt; utility substitution command to replace the entire line with only the portion in between the word ‘took ‘ and the word ‘ ms’:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.txt  | grep &quot;event #0&quot; | sed -ne 's/.*took \([0-9]*\) ms/\1/p'
11418
26063
30484
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now how do we make sense of this data?  Especially if the result contains hundreds or thousands of records, how can we begin to understand the data?  One quick way is to calculate the average, minimum and maximum values.  This can be done using an awk script (For details on the calc.sh script reference the blog post &lt;a href=&quot;https://mode19.github.io/humanreadable/awk,/unix/2018/03/01/Quick-and-dirty-software-metrics-using-awk.html&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logfile.text | grep &quot;event #0&quot; | sed -ne 's/.*took \([0-9]*\) ms/\1/p' | ~/bin/calc.sh
sum     count   average medium  min     max
67965   3       22655   26063   11418   30484
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion-and-next-steps&quot;&gt;Conclusion and Next Steps&lt;/h2&gt;

&lt;p&gt;Using these techniques we can analyze large log files to search for specific values or events. These techniques can work when querying a single file or combining multiple files together. Also, since these techniques are done on the command-line they can be easily scripts and repeated or executed in an automated fashion.  With a few basic scrips one can develop sophisticated techniques for measuring software metrics. Check back for future articles on how to take these metrics and seamlessly create graphs using the gnuplot command-line utility.&lt;/p&gt;</content><author><name></name></author><summary type="html">Introduction When troubleshooting software we usually don’t have all the required information in one place. Often we only have command-line access to low level application and system log files. Command line tools such as tail, cat, grep etc. can be combined to provide basic insights into application performance. Lets look at some examples of how to use standard UNIX command-line tools to analyze application log files.</summary></entry><entry><title type="html">Welcome to the Blog</title><link href="https://mode19.github.io/humanreadable/admin/2017/01/01/welcome.html" rel="alternate" type="text/html" title="Welcome to the Blog" /><published>2017-01-01T00:00:00-05:00</published><updated>2017-01-01T00:00:00-05:00</updated><id>https://mode19.github.io/humanreadable/admin/2017/01/01/welcome</id><content type="html" xml:base="https://mode19.github.io/humanreadable/admin/2017/01/01/welcome.html">&lt;p&gt;I believe it was Albert Einstein that said: “If you’re not learning you’re dying”.  Thruthfully, this quote and attribution come to me via pinterest but regardless of the source, the idea rings true to me. The mental state of learning is not something to turn to periodically when life requires it but rather a process that is part of life itself.&lt;/p&gt;

&lt;p&gt;As a software developer I am constantly exploring new technologies and tinkering with a wide variety of tools. This blog is intended to share some of those ideas and learnings.&lt;/p&gt;

&lt;p&gt;Some ideas for topics I may tackle in the future:&lt;/p&gt;

&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; width=&quot;586pt&quot; height=&quot;166pt&quot; viewBox=&quot;0.00 0.00 586.02 165.62&quot;&gt;
&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 161.622)&quot;&gt;
&lt;title&gt;ideas&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;none&quot; points=&quot;-4,4 -4,-161.622 582.016,-161.622 582.016,4 -4,4&quot;&gt;&lt;/polygon&gt;

&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;&lt;title&gt;Ideas&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;276.033&quot; cy=&quot;-127.217&quot; rx=&quot;45.9239&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;262.033&quot; y=&quot;-123.017&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Ideas&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;&lt;title&gt;Design&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;53.033&quot; cy=&quot;-30.4056&quot; rx=&quot;53.066&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;34.033&quot; y=&quot;-26.2056&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Design&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;&lt;title&gt;Ideas-&amp;gt;Design&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M236.732,-110.975C203.971,-98.0974 156.182,-78.9099 115.033,-60.8112 110.872,-58.981 106.574,-57.0432 102.273,-55.0704&quot;&gt;&lt;/path&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;103.446,-51.7565 92.9013,-50.7241 100.5,-58.1068 103.446,-51.7565&quot;&gt;&lt;/polygon&gt;
&lt;/g&gt;

&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;&lt;title&gt;Code&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;170.033&quot; cy=&quot;-30.4056&quot; rx=&quot;45.9239&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;156.033&quot; y=&quot;-26.2056&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Code&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;&lt;title&gt;Ideas-&amp;gt;Code&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M249.285,-102.292C235.727,-90.165 219.102,-75.2954 204.587,-62.3122&quot;&gt;&lt;/path&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;206.56,-59.3808 196.773,-55.3228 201.893,-64.5983 206.56,-59.3808&quot;&gt;&lt;/polygon&gt;
&lt;/g&gt;

&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;&lt;title&gt;Test&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;276.033&quot; cy=&quot;-30.4056&quot; rx=&quot;42.3529&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;264.033&quot; y=&quot;-26.2056&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Test&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;&lt;title&gt;Ideas-&amp;gt;Test&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M276.033,-96.7376C276.033,-88.6219 276.033,-79.6842 276.033,-71.0939&quot;&gt;&lt;/path&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;279.533,-70.8665 276.033,-60.8665 272.533,-70.8665 279.533,-70.8665&quot;&gt;&lt;/polygon&gt;
&lt;/g&gt;

&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;&lt;title&gt;Deploy&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;390.033&quot; cy=&quot;-30.4056&quot; rx=&quot;53.9813&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;370.033&quot; y=&quot;-26.2056&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Deploy&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;&lt;title&gt;Ideas-&amp;gt;Deploy&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M303.921,-103.023C318.515,-90.8855 336.59,-75.8528 352.406,-62.6987&quot;&gt;&lt;/path&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;354.991,-65.1018 360.441,-56.0165 350.515,-59.7199 354.991,-65.1018&quot;&gt;&lt;/polygon&gt;
&lt;/g&gt;

&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;&lt;title&gt;Monitor&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;520.033&quot; cy=&quot;-30.4056&quot; rx=&quot;57.9655&quot; ry=&quot;30.3115&quot;&gt;&lt;/ellipse&gt;
&lt;text text-anchor=&quot;start&quot; x=&quot;497.033&quot; y=&quot;-26.2056&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;Monitor&lt;/text&gt;
&lt;/g&gt;

&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;&lt;title&gt;Ideas-&amp;gt;Monitor&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M316.011,-112.212C352.056,-99.4038 406.404,-79.6394 453.033,-60.8112 457.77,-58.8983 462.673,-56.8607 467.572,-54.7847&quot;&gt;&lt;/path&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;469.131,-57.9244 476.944,-50.768 466.373,-51.4904 469.131,-57.9244&quot;&gt;&lt;/polygon&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;

&lt;ul&gt;
  &lt;li&gt;Design
    &lt;ul&gt;
      &lt;li&gt;Introduction to UML Diagrams&lt;/li&gt;
      &lt;li&gt;Generating UML diagrams from Code&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Code
    &lt;ul&gt;
      &lt;li&gt;Using Jetty Servlet Container: Embedded v.s Stand-alone&lt;/li&gt;
      &lt;li&gt;Eclipse Che project - Coding in the Cloud&lt;/li&gt;
      &lt;li&gt;Using VIM as a Node.js/JavaScript IDE&lt;/li&gt;
      &lt;li&gt;Maintaining Data Integrity with JSON Schema&lt;/li&gt;
      &lt;li&gt;Introduction to Json Path&lt;/li&gt;
      &lt;li&gt;The Zen of XML Transformations: XSLT and Xpath Basics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Test
    &lt;ul&gt;
      &lt;li&gt;Automated Web Interface Testing with Selenium Java API&lt;/li&gt;
      &lt;li&gt;Load testing with Jmeter on DigitalOcean&lt;/li&gt;
      &lt;li&gt;Using Selenium with Node.js: Webdriver.io Project&lt;/li&gt;
      &lt;li&gt;Load testing with Python and locust.io on DigitalOcean&lt;/li&gt;
      &lt;li&gt;Automated Testing of JSON Web Services using Rest-Assured&lt;/li&gt;
      &lt;li&gt;Recording and Playing-back Data: Introduction to Wiremock Server&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deploy
    &lt;ul&gt;
      &lt;li&gt;Introduction to Running Hyper-SQL Database Server&lt;/li&gt;
      &lt;li&gt;Implementing CICD (Continuous Integration and Continuous Deployment)&lt;/li&gt;
      &lt;li&gt;Generating Test Reports using Jenkins&lt;/li&gt;
      &lt;li&gt;Introduction to Docker&lt;/li&gt;
      &lt;li&gt;MongoDB Basics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Monitor
    &lt;ul&gt;
      &lt;li&gt;Linux Performance Monitoring&lt;/li&gt;
      &lt;li&gt;Monitor Java JVM Memory with JMX and Jconsole&lt;/li&gt;
      &lt;li&gt;Creating Graphs on the Command-line using Gnuplot&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope to provide concise, useful and interesting articles on these and other topics.&lt;/p&gt;

&lt;p&gt;Welcome to the blog and please check back soon for more articles!&lt;/p&gt;</content><author><name></name></author><summary type="html">I believe it was Albert Einstein that said: “If you’re not learning you’re dying”. Thruthfully, this quote and attribution come to me via pinterest but regardless of the source, the idea rings true to me. The mental state of learning is not something to turn to periodically when life requires it but rather a process that is part of life itself.</summary></entry></feed>